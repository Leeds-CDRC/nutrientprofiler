---
title: "Handling input data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Handling input data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Input data is likely to be messy and to not contain the required column names for `nutrientprofiler`.
This vignette provides some advice and guidelines on how to pre-process your data to allow analysis
and assessment with `nutrientprofiler`.

You can see what parameters are expected in more detail in the [Example dataset reference](../reference/cdrcdrinks.html).
The order of parameters in the loaded data do not matter.

```{r setup, echo=FALSE}
library(nutrientprofiler)

irregular_data <- cdrcdrinks
names(irregular_data)[names(irregular_data) == "fvn_measurement_percent"] <- "fruit_nutrition_percent"

missing_data <- cdrcdrinks
missing_data <- missing_data[-c(2, 3)]

incomplete_data <- cdrcdrinks
# incomplete_data[2,"product_type"] <- ""
# incomplete_data[3,"product_type"] <- NA

incomplete_data[1,"sugar_measurement_g"] <- ""
incomplete_data[2,"sugar_measurement_g"] <- ""
incomplete_data[4,"sugar_measurement_g"] <- ""
```

## Loading an example template

When possible, it is a good idea to ensure your data is in the required format before yourload it in to R. This can be achieved by using a template.

The `nutrientprofiler` package offers an example dataset, `cdrcdrinks`. This can be saved out as an
example csv file and then edited and loaded with real data:

```R
# Save an example csv file to your current working directory
write.csv(cdrcdrinks, "template_full.csv", row.names = FALSE)
```

Alternatively, just the headers can be saved, providing a blank csv file which can be opened in
Excel or your editor of choice:

```R
# Save an example csv file to your current working directory
write.csv(t(names(cdrcdrinks)), "template_headings.csv", row.names = FALSE)
```

## Checking column names and renaming parameters

If raw data has been acquired with different column names than required, a reproducible
workflow can be set up to rename these parameters as required.

The first step is to check the existing column names:

```{r}
inputDataCheck(cdrcdrinks)
```

If the dataframe contains names as expected, you'll get a message telling you to proceed with analysis,
as with the example dataset above.

However, lets say we have loaded in a dataset from csv `irregular_data` that does not contain the
exact columns required:

```{r}
inputDataCheck(irregular_data)
```

This provides you with the name of the column(s) that do not match an expected column name
(`"fruit_nutrition_percent"` in this example), and provides you with a prompt to use the
`parameterRename()` function.

You can copy this hint and replace `<INSERT DATA COLUMN NAME HERE>` with the data that matches
the listed `missing_column_name`:

```{r}
irregular_data <- parameterRename(missing_column_name = 'fvn_measurement_percent', associated_data_column = 'fruit_nutrition_percent', data_frame = irregular_data)
```

You can now check again if the required parameters are available.

```{r}
inputDataCheck(irregular_data)
```

## Missing parameters

Some of the parameters are optional, but still need an allocated column in the input data table.
This column can be simply filled with `NA` values. `nutrientprofiler` provides some simple functions
to help achieve this quickly.

You can see if we run the `inputDataCheck` there are no returns for "unmatched columns", suggesting
that the data is missing as opposed to unlabelled:

```{r}
inputDataCheck(missing_data)
```

We can store the list of missing parameters by using the `listMissingParameters` function:
```{r}
missing_params <- listMissingParameters(missing_data)

print(missing_params)
```

If we are happy that these are optional parameters that can be filled with `NA` values,
we can pass this list (or a subset of it) to the `fillMissingParameters` function:

```{r}
filled_data <- fillMissingParameters(missing_data, missing_params)

filled_data
```

This then allows the data to be processed in bulk without triggerring errors related to
missing data.

## Missing data

Certain parameters are only required for certain product types, so we have included some functions to check if the necessary parameters are present for each specific product.

### Find out what data is missing

```{r}
report_table <- ReqParamCheck(incomplete_data)
```

We can transpose and print this table to see how many rows are missing values for each parameter:

```{r}
t(report_table)
```

In addition, there are certain parameters that have automatically assigned defaults if they are missing (`"drink_format", "food_type", "drink_type"`). You can also check if these parameters are missing using the `AutoDefaultParamCheck()` function. This adds the indices of rows missing these values to the report dataframe object:

```{r}
report_table <- AutoDefaultParamCheck(incomplete_data, report_table)
```

These "automatic defaults" can be recorded in the dataframe of product data by using the `AutoDefaultParamNote()` function, in the `default_params_used` column:

```{r}
incomplete_data <- AutoDefaultParamNote(incomplete_data, report_table)

incomplete_data
```

We can use the report generated by `ReqParamCheck()` and `AutoDefaultParamCheck()` to discover what parameters are missing in more detail. When we printed the transposed report table above (using `t(report_table)`), we saw that some parameters read `NA` - these are optional parameters that were not checked. Some parameters read `integer, 0` meaning that these parameters were checked, and no data is missing from product entries where that parameter is required. Where data is missing, `integer, NUM` is repeated with a non-zero value in place of `NUM`, for example `sugar_measurement_g` reads `integer, 3`. You can interogate which product entries are missing data for `sugar_measurement_g` using the double bracket notation:

```{r}
report_table$sugar_measurement_g[[1]]
```

### Fill missing data

We can enter data for `sugar_measurement_g` in products with the indices `1 2 4` using the `ManualParamUpdate()` function. This function takes the following arguments: `data_frame`, the product data.frame object being analysed, in this case `incomplete_data`; `parameter_name` - in this case `"sugar_measurement_g"`; `index_list` - these can be supplied manually or from the report as shown above; `value` - the value to set the parameter to for these rows. We are going to use an unrealistically high value of `100.0` in order to clearly see where this has been applied.

```{r}
updated_data <- ManualParamUpdate(
  incomplete_data,
  "sugar_measurement_g",
  report_table$sugar_measurement_g[[1]],
  100.0)
```

Where values are required to be numeric, we can coerce the values to a numeric type:
```R
updated_data$sugar_measurement_g <- as.numeric(updated_data$sugar_measurement_g)
```

We can see the updated `sugar_measurement_g` values in our dataframe, before and after the coercion:

```{r}
# Update sugar values:
print(updated_data$sugar_measurement_g)

updated_data$sugar_measurement_g <- as.numeric(updated_data$sugar_measurement_g)

# Record of where parameters have been manually edited/applied:
print(updated_data$manual_params_used)
```

This updated dataframe can then be used in the analysis workflow examples given in this documentation:

```{r}
library(tidyr)
library(dplyr)

updated_data_results <- updated_data %>% 
  rowwise() %>% 
  mutate( sg = SGConverter(pick(everything()))) %>% 
  mutate(test = NPMScore(pick(everything()), sg_adjusted_label="sg")) %>% 
  unnest(test) %>% 
  rowwise() %>%
  mutate(assess = NPMAssess(pick(everything()))) %>%
  unnest(assess) %>%
  select(everything(), energy_score, sugar_score, salt_score, fvn_score,
  protein_score, satfat_score, fibre_score, NPM_score, NPM_assessment)
```

## Checking for incorrect data
